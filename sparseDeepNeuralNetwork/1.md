maxLayers = 120 * [1, 4, 16]

for j=1:length(maxLayers)
    for k=1:maxLayers(j)
        read each layer

    inferenceReLUvec(layers,bias,featureVectors) % where layers[120 or 1920, 1024 or 65536], bias [120 or 1920, 1], featureVectors[60k *1024](6m line for 1024, 10%) *64   0.3B
        Y= featureVectors
        for 120
            z = Y*W{i} + (double(logical(Y*W{i})) .* bias{i});


memory usage 
    featureVectors 12m int= 48MB   (*64) =3GB  0.4KB -25kb per item
    layers 120* 1k *1k  480MB *16 *64= 480GB   4M -256M per layer ,120KB-8MB 
    logical 1k - 64k 


    
how to pipeline
    stream over layer


C=A[m,n]*B[n,l]

C[a,b]=\sigma A[a,i]B[i,b]


<!-- 1. spmspv(csr,v,v)
2. v to csc
3. csc to csr -->



1. each block process a item, can store in shared memory.
2. thus no need to format convert.

on cpu ?